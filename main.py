# main.py - Versi√≥n FINAL CORREGIDA

import os
import json
import base64
import audioop
import io
import wave
import asyncio
import time
import logging
from functools import partial
from typing import Optional
from fastapi import FastAPI, WebSocket, Request, Form
from fastapi.responses import HTMLResponse, Response
from fastapi.websockets import WebSocketDisconnect
from dotenv import load_dotenv
from agent import agent_reply
from ibm_cloud_sdk_core.authenticators import IAMAuthenticator
from ibm_watson import SpeechToTextV1, TextToSpeechV1
from recording_manager import CallRecorder

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

load_dotenv()

# Configuraci√≥n
IBM_STT_APIKEY = os.getenv("IBM_STT_APIKEY")
IBM_STT_URL = os.getenv("IBM_STT_URL")
IBM_TTS_APIKEY = os.getenv("IBM_TTS_APIKEY")
IBM_TTS_URL = os.getenv("IBM_TTS_URL")

# Timeouts optimizados
STT_TIMEOUT = 8
AGENT_TIMEOUT = 12
TTS_TIMEOUT = 20
ACTIVITY_TIMEOUT = 30
DUPLICATE_RESPONSE_THRESHOLD = 3
WEBSOCKET_PING_INTERVAL = 10

# Par√°metros de buffer y detecci√≥n de silencio
MIN_BUFFER_SIZE = 16000  # 2 segundos
MAX_BUFFER_SIZE = 64000  # 8 segundos
SILENCE_THRESHOLD = 200
SILENCE_DURATION = 0.8
SILENCE_CHUNKS = int((SILENCE_DURATION * 8000) / 160)

app = FastAPI()

# IBM STT
stt_auth = IAMAuthenticator(IBM_STT_APIKEY)
stt = SpeechToTextV1(authenticator=stt_auth)
stt.set_service_url(IBM_STT_URL)

# IBM TTS
tts_auth = IAMAuthenticator(IBM_TTS_APIKEY)
tts = TextToSpeechV1(authenticator=tts_auth)
tts.set_service_url(IBM_TTS_URL)


def is_silence(audio_chunk: bytes) -> bool:
    """Detecta si un chunk de audio es silencio"""
    try:
        pcm = audioop.ulaw2lin(audio_chunk, 2)
        rms = audioop.rms(pcm, 2)
        return rms < SILENCE_THRESHOLD
    except:
        return False


def convert_mulaw_to_pcm_16k(mulaw_data):
    """Convierte audio Œº-law 8kHz a PCM linear 16kHz para IBM Watson STT"""
    try:
        logger.info(f"üîÑ Convirtiendo {len(mulaw_data)} bytes de Œº-law...")
        unique_bytes = len(set(mulaw_data))
        
        if unique_bytes < 5:
            logger.warning(f"   ‚ö†Ô∏è  Audio parece ser silencio")
            raise ValueError("Audio es silencio")
        
        pcm_data = audioop.ulaw2lin(mulaw_data, 2)
        rms_original = audioop.rms(pcm_data, 2)
        logger.info(f"   üìä Volumen RMS original: {rms_original}")
        
        pcm_16k, _ = audioop.ratecv(pcm_data, 2, 1, 8000, 16000, None)
        rms = audioop.rms(pcm_16k, 2)
        logger.info(f"   üìä Volumen RMS final: {rms}")
        
        if rms < 300:
            factor = min(3.0, 900 / max(rms, 1))
            logger.info(f"   üìä Amplificando audio {factor:.1f}x")
            pcm_16k = audioop.mul(pcm_16k, 2, factor)
            rms_final = audioop.rms(pcm_16k, 2)
            logger.info(f"   ‚úì RMS despu√©s de amplificar: {rms_final}")
        
        return pcm_16k
    except Exception as e:
        logger.error(f"‚ùå Error en conversi√≥n de audio: {e}")
        raise


def convert_wav_to_mulaw_8k(wav_data):
    """Convierte WAV a Œº-law 8kHz para Twilio"""
    try:
        with wave.open(io.BytesIO(wav_data), 'rb') as wav_file:
            params = wav_file.getparams()
            frames = wav_file.readframes(params.nframes)
            
            if params.framerate != 8000:
                frames, _ = audioop.ratecv(
                    frames,
                    params.sampwidth,
                    params.nchannels,
                    params.framerate,
                    8000,
                    None
                )
            
            if params.nchannels == 2:
                frames = audioop.tomono(frames, params.sampwidth, 1, 1)
            
            mulaw_audio = audioop.lin2ulaw(frames, params.sampwidth)
            return mulaw_audio
    except Exception as e:
        logger.error(f"‚ùå Error convirtiendo WAV a Œº-law: {e}")
        raise


async def send_audio_to_twilio(ws, stream_sid, text, voice="es-LA_SofiaV3Voice", mark_name=None):
    """
    Convierte texto a audio y lo env√≠a a Twilio con mark events para sincronizaci√≥n.
    CORRECCI√ìN CLAVE: Usa eventos 'mark' en lugar de sleep para evitar bloqueos.
    """
    try:
        logger.info(f"üìä Generando audio para: '{text[:50]}...'")
        
        loop = asyncio.get_event_loop()
        audio_reply = await asyncio.wait_for(
            loop.run_in_executor(
                None,
                lambda: tts.synthesize(
                    text=text,
                    accept="audio/wav",
                    voice=voice
                ).get_result().content
            ),
            timeout=TTS_TIMEOUT
        )

        mulaw_audio = convert_wav_to_mulaw_8k(audio_reply)
        duration_seconds = len(mulaw_audio) / 8000
        logger.info(f"‚è±Ô∏è  Duraci√≥n del audio: {duration_seconds:.1f}s")
        
        # Generar un mark √∫nico si no se proporcion√≥
        if mark_name is None:
            mark_name = f"audio_{int(time.time() * 1000)}"
        
        chunk_size = 160
        chunks_sent = 0
        
        # Enviar todos los chunks de audio
        for i in range(0, len(mulaw_audio), chunk_size):
            chunk = mulaw_audio[i:i+chunk_size]
            chunk_b64 = base64.b64encode(chunk).decode()
            
            await ws.send_json({
                "event": "media",
                "streamSid": stream_sid,
                "media": {"payload": chunk_b64}
            })
            chunks_sent += 1
            
            if chunks_sent % 50 == 0:
                await asyncio.sleep(0.01)
        
        # CORRECCI√ìN CR√çTICA: Enviar evento 'mark' al final del audio
        await ws.send_json({
            "event": "mark",
            "streamSid": stream_sid,
            "mark": {"name": mark_name}
        })
        
        logger.info(f"‚úÖ Audio enviado ({chunks_sent} chunks) + mark '{mark_name}'")
        
        del mulaw_audio
        del audio_reply
        
        return mark_name
        
    except asyncio.TimeoutError:
        logger.error(f"‚è±Ô∏è Timeout generando audio TTS")
        raise
    except Exception as e:
        logger.error(f"‚ùå Error enviando audio: {e}")
        raise


async def send_greeting(ws, stream_sid):
    """Env√≠a saludo inicial"""
    greeting = "Hola, ¬øen qu√© puedo ayudarte?"
    logger.info("ü§ñ Enviando saludo inicial...")
    return await send_audio_to_twilio(ws, stream_sid, greeting, mark_name="greeting")


async def recognize_with_timeout(pcm_audio, timeout=STT_TIMEOUT) -> Optional[dict]:
    """Ejecuta IBM STT con timeout"""
    loop = asyncio.get_event_loop()
    
    spanish_models = [
        "es-MX_BroadbandModel",
        "es-ES_BroadbandModel", 
        "es-LA_BroadbandModel"
    ]
    
    for model in spanish_models:
        try:
            logger.info(f"üéØ STT con modelo: {model}")
            
            result = await asyncio.wait_for(
                loop.run_in_executor(
                    None,
                    partial(
                        stt.recognize,
                        audio=pcm_audio,
                        content_type="audio/l16; rate=16000",
                        model=model,
                        smart_formatting=True,
                        max_alternatives=1,
                        inactivity_timeout=5,
                        background_audio_suppression=0.5,
                        speech_detector_sensitivity=0.5,
                    )
                ),
                timeout=timeout
            )
            
            result_dict = result.get_result()
            
            if result_dict and result_dict.get("results"):
                alternatives = result_dict["results"][0].get("alternatives", [])
                if alternatives and alternatives[0].get("transcript", "").strip():
                    logger.info(f"‚úÖ Transcripci√≥n con {model}")
                    return result_dict
            
            logger.info(f"‚ö†Ô∏è Sin transcripci√≥n en {model}, probando siguiente...")
            
        except asyncio.TimeoutError:
            logger.warning(f"‚è±Ô∏è Timeout en {model}")
            continue
        except Exception as e:
            logger.error(f"‚ùå Error en {model}: {e}")
            continue
    
    logger.warning("‚ùå Ning√∫n modelo STT funcion√≥")
    return None


async def agent_reply_async(text: str, timeout=AGENT_TIMEOUT) -> str:
    """Wrapper as√≠ncrono para agent_reply con timeout"""
    loop = asyncio.get_event_loop()
    try:
        reply = await asyncio.wait_for(
            loop.run_in_executor(None, agent_reply, text),
            timeout=timeout
        )
        return reply
    except asyncio.TimeoutError:
        logger.error("‚è±Ô∏è Timeout en agent_reply")
        return "Lo siento, estoy teniendo problemas para procesar tu solicitud."
    except Exception as e:
        logger.error(f"‚ùå Error en agent_reply: {e}")
        return "Disculpa, ocurri√≥ un error. ¬øPuedes repetir?"


async def keep_alive(ws):
    """Mantiene la conexi√≥n activa con pings peri√≥dicos"""
    try:
        while True:
            await asyncio.sleep(WEBSOCKET_PING_INTERVAL)
            await ws.send_json({"event": "keepalive"})
            logger.debug("üíì Keepalive enviado")
    except asyncio.CancelledError:
        pass
    except Exception as e:
        logger.error(f"‚ùå Error en keepalive: {e}")


def generate_twiml(host: str) -> str:
    """
    Genera el TwiML response con la URL del WebSocket.
    NOTA: No incluir <Record> cuando usas <Stream> - son mutuamente exclusivos.
    """
    return f"""<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Connect>
        <Stream url="wss://{host}/media-stream" />
    </Connect>
</Response>"""


# ========================================
# HTTP ENDPOINTS
# ========================================

@app.get("/")
async def index():
    return HTMLResponse("""
        <h1>ü§ñ Twilio Voice Bot</h1>
        <p>WebSocket endpoint: <code>/media-stream</code></p>
        <p>Status: ‚úÖ Running</p>
    """)


@app.post("/twiml")
async def handle_twiml(request: Request):
    """Endpoint principal para TwiML"""
    # Obtener el host del header o request
    host = request.headers.get("host") or str(request.base_url).replace("http://", "").replace("https://", "").rstrip("/")
    
    logger.info(f"üìû Llamada entrante desde host: {host}")
    
    twiml = generate_twiml(host)
    return Response(content=twiml, media_type="application/xml")


@app.post("/incoming-call")
async def incoming_call(request: Request):
    """Alias para /twiml"""
    return await handle_twiml(request)


@app.post("/voice")
async def voice(request: Request):
    """Otro alias com√∫n para /twiml"""
    return await handle_twiml(request)


@app.post("/recording-status")
async def recording_status(request: Request):
    """
    Endpoint para recibir callbacks de estado de grabaci√≥n de Twilio.
    NOTA: Este endpoint ya no es necesario porque manejamos grabaci√≥n internamente,
    pero lo mantenemos por compatibilidad.
    """
    form_data = await request.form()
    logger.info(f"üìù Recording status callback: {dict(form_data)}")
    return {"status": "received"}


# ========================================
# WEBSOCKET ENDPOINT
# ========================================

@app.websocket("/media-stream")
async def handle_media_stream(ws: WebSocket):
    """
    WebSocket endpoint principal para Twilio Media Streams.
    CORRECCIONES:
    1. Usa eventos 'mark' para sincronizaci√≥n (no sleep)
    2. Endpoint correcto: /media-stream
    3. Manejo de grabaci√≥n interno (no usa <Record> de Twilio)
    """
    await ws.accept()
    logger.info("‚úÖ WebSocket conectado en /media-stream")
    
    # Estado de la conversaci√≥n
    stream_sid = None
    call_sid = None
    has_greeted = False
    is_speaking = False
    audio_buffer = b""
    chunks_received = 0
    consecutive_silence_chunks = 0
    has_speech = False
    last_response_time = 0
    recorder = None
    
    # Rastrear marks pendientes (CORRECCI√ìN CLAVE)
    pending_marks = set()
    current_mark = None
    
    keep_alive_task = asyncio.create_task(keep_alive(ws))
    
    try:
        async for message in ws.iter_text():
            data = json.loads(message)
            
            if data["event"] == "start":
                stream_sid = data["start"]["streamSid"]
                call_sid = data["start"].get("callSid", "unknown")
                logger.info(f"üìû Stream iniciado: {stream_sid}")
                logger.info(f"üìû Call SID: {call_sid}")
                
                media_format = data["start"].get("mediaFormat", {})
                logger.info(f"üìã Format: {json.dumps(media_format, indent=2)}")
                
                # üé¨ Iniciar grabaci√≥n interna
                try:
                    storage_type = os.getenv("RECORDING_STORAGE", "local")
                    recorder = CallRecorder(call_sid, storage_type=storage_type)
                    recorder.start_recording()
                    logger.info(f"üé¨ Grabaci√≥n iniciada (storage: {storage_type})")
                except Exception as e:
                    logger.error(f"‚ùå Error iniciando grabaci√≥n: {e}")
                    recorder = None
                
                if not has_greeted:
                    has_greeted = True
                    is_speaking = True
                    
                    try:
                        mark_name = await send_greeting(ws, stream_sid)
                        pending_marks.add(mark_name)
                        current_mark = mark_name
                        logger.info(f"üéØ Esperando mark: {mark_name}")
                    except Exception as e:
                        logger.error(f"‚ùå Error saludo: {e}")
                        is_speaking = False
                    
                    # Resetear buffers
                    audio_buffer = b""
                    chunks_received = 0
                    consecutive_silence_chunks = 0
                    has_speech = False

            # CORRECCI√ìN CLAVE: Manejar evento 'mark' de Twilio
            elif data["event"] == "mark":
                mark_name = data["mark"]["name"]
                logger.info(f"‚úÖ Mark recibido: {mark_name}")
                
                if mark_name in pending_marks:
                    pending_marks.remove(mark_name)
                
                # Si este era el mark actual y no hay m√°s marks pendientes
                if mark_name == current_mark and len(pending_marks) == 0:
                    is_speaking = False
                    current_mark = None
                    logger.info("üëÇ Listo para escuchar (mark confirmado)")

            elif data["event"] == "media":
                # Solo ignorar audio si hay marks pendientes
                if is_speaking and len(pending_marks) > 0:
                    continue
                
                audio_b64 = data["media"]["payload"]
                audio_bytes = base64.b64decode(audio_b64)
                
                # üé¨ Grabar cada chunk
                if recorder and recorder.is_recording:
                    try:
                        recorder.add_audio_chunk(audio_bytes)
                    except Exception as e:
                        logger.error(f"‚ùå Error grabando chunk: {e}")
                
                chunks_received += 1
                
                # Detectar silencio puro
                if audio_bytes == b'\xff' * len(audio_bytes) or audio_bytes == b'\x00' * len(audio_bytes):
                    consecutive_silence_chunks += 1
                    continue
                
                # Protecci√≥n contra buffer overflow
                if len(audio_buffer) > MAX_BUFFER_SIZE:
                    logger.warning(f"‚ö†Ô∏è Buffer excedi√≥ {MAX_BUFFER_SIZE} bytes, reseteando")
                    audio_buffer = b""
                    chunks_received = 0
                    consecutive_silence_chunks = 0
                    has_speech = False
                    continue
                
                # Detecci√≥n de silencio
                if is_silence(audio_bytes):
                    consecutive_silence_chunks += 1
                else:
                    if consecutive_silence_chunks > 0:
                        logger.debug(f"üîä Habla detectada despu√©s de {consecutive_silence_chunks} chunks silencio")
                    consecutive_silence_chunks = 0
                    has_speech = True
                
                audio_buffer += audio_bytes
                
                if chunks_received % 100 == 0:
                    seconds_recorded = len(audio_buffer) / 8000
                    logger.info(f"üì¶ Buffer: {seconds_recorded:.1f}s")
                
                should_process = False
                
                # Condici√≥n 1: Buffer m√≠nimo + habla + pausa detectada
                if len(audio_buffer) >= MIN_BUFFER_SIZE and has_speech:
                    if consecutive_silence_chunks >= SILENCE_CHUNKS:
                        logger.info(f"‚úÖ Pausa detectada ({consecutive_silence_chunks} chunks silencio)")
                        should_process = True
                
                # Condici√≥n 2: Buffer m√°ximo alcanzado
                elif len(audio_buffer) >= MAX_BUFFER_SIZE:
                    logger.info(f"‚úÖ Buffer m√°ximo alcanzado")
                    should_process = True
                
                if not should_process:
                    continue
                
                # PROCESAR AUDIO
                buffer_seconds = len(audio_buffer) / 8000
                logger.info(f"üé§ Procesando {buffer_seconds:.1f}s de audio")
                
                is_speaking = True
                current_buffer = audio_buffer
                audio_buffer = b""
                chunks_received = 0
                consecutive_silence_chunks = 0
                has_speech = False
                
                try:
                    # Validar que no sea silencio
                    unique_bytes = len(set(current_buffer))
                    if unique_bytes < 10:
                        logger.warning(f"‚ö†Ô∏è Solo {unique_bytes} valores √∫nicos (silencio)")
                        is_speaking = False
                        continue
                    
                    # Convertir audio
                    try:
                        pcm_audio = convert_mulaw_to_pcm_16k(current_buffer)
                    except ValueError as e:
                        logger.warning(f"‚ö†Ô∏è Audio inv√°lido: {e}")
                        is_speaking = False
                        continue
                    except Exception as e:
                        logger.error(f"‚ùå Error conversi√≥n: {e}")
                        is_speaking = False
                        continue
                    
                    logger.info(f"üìä PCM: {len(pcm_audio)} bytes")
                    
                    # Speech-to-Text
                    result = await recognize_with_timeout(pcm_audio, timeout=STT_TIMEOUT)
                    
                    del current_buffer
                    del pcm_audio
                    
                    if not result:
                        logger.warning("‚ö†Ô∏è STT sin resultado")
                        is_speaking = False
                        continue
                    
                    # Extraer texto y confianza
                    text = ""
                    confidence = 0
                    if result.get("results") and len(result["results"]) > 0:
                        alternatives = result["results"][0].get("alternatives", [])
                        if alternatives and len(alternatives) > 0:
                            text = alternatives[0].get("transcript", "").strip()
                            confidence = alternatives[0].get("confidence", 0)
                            logger.info(f"üìù '{text}' (conf: {confidence:.2f})")
                    
                    # Validar texto
                    if not text or len(text) < 3 or confidence < 0.5:
                        logger.warning(f"‚ö†Ô∏è Rechazado: '{text}' (conf: {confidence:.2f})")
                        is_speaking = False
                        continue
                    
                    logger.info(f"üí¨ User: {text}")
                    
                    # Prevenir respuestas duplicadas
                    current_time = time.time()
                    if last_response_time > 0 and current_time - last_response_time < DUPLICATE_RESPONSE_THRESHOLD:
                        logger.info("‚è≠Ô∏è Ignorado (respuesta reciente)")
                        is_speaking = False
                        continue
                    
                    # Obtener respuesta del agente
                    reply = await agent_reply_async(text, timeout=AGENT_TIMEOUT)
                    logger.info(f"ü§ñ Agent: {reply[:100]}...")
                    
                    try:
                        # Enviar audio con mark (CORRECCI√ìN CLAVE)
                        mark_name = await asyncio.wait_for(
                            send_audio_to_twilio(ws, stream_sid, reply),
                            timeout=TTS_TIMEOUT + 5
                        )
                        
                        # Agregar mark a pendientes
                        pending_marks.add(mark_name)
                        current_mark = mark_name
                        logger.info(f"üéØ Esperando mark: {mark_name}")
                        
                        last_response_time = time.time()
                        
                    except asyncio.TimeoutError:
                        logger.error("‚è±Ô∏è Timeout TTS")
                        is_speaking = False
                    except Exception as e:
                        logger.error(f"‚ùå Error TTS: {e}")
                        is_speaking = False
                    
                except Exception as e:
                    logger.error(f"‚ùå Error procesamiento: {e}")
                    import traceback
                    traceback.print_exc()
                    is_speaking = False

            elif data["event"] == "stop":
                logger.info("üî¥ Stream stopped")
                
                # üé¨ Finalizar y subir grabaci√≥n
                if recorder and recorder.is_recording:
                    logger.info("üíæ Finalizando grabaci√≥n...")
                    try:
                        recording_url = await recorder.finalize()
                        if recording_url:
                            logger.info(f"üé¨ ‚úÖ Grabaci√≥n disponible: {recording_url}")
                        else:
                            logger.warning("‚ö†Ô∏è No se pudo guardar la grabaci√≥n")
                    except Exception as e:
                        logger.error(f"‚ùå Error finalizando grabaci√≥n: {e}")
                
                break

    except WebSocketDisconnect:
        logger.info("‚ùå Client disconnected")
    except Exception as e:
        logger.error(f"‚ùå Error fatal: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # üé¨ Backup: Guardar grabaci√≥n en caso de cierre inesperado
        if recorder and recorder.is_recording:
            logger.info("üíæ Guardando grabaci√≥n por cierre inesperado...")
            try:
                recording_url = await recorder.finalize()
                if recording_url:
                    logger.info(f"üé¨ ‚úÖ Grabaci√≥n guardada: {recording_url}")
            except Exception as e:
                logger.error(f"‚ùå Error guardando grabaci√≥n: {e}")
        
        keep_alive_task.cancel()
        try:
            await keep_alive_task
        except asyncio.CancelledError:
            pass
        
        is_speaking = False
        audio_buffer = b""
        logger.info("üßπ Limpieza completa")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
